\select@language {english}
\addvspace {4\p@ }
\addvspace {4\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces Schema of a process.\relax }}{3}{figure.caption.8}
\addvspace {4\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces On the left, MLP consisting of input layer with two units, two hidden layers with four and three units respectively, and output layer with two units. Schematic diagram of the MLP's layers on the right.\relax }}{7}{figure.caption.9}
\contentsline {figure}{\numberline {3.2}{\ignorespaces On the left, Elman's recurrent network with input, hidden, context, and output layer, each containing two units. On the right, schema of layers in Elman network. Dotted link signifies copying activity of source units to target units.\relax }}{11}{figure.caption.10}
\contentsline {figure}{\numberline {3.3}{\ignorespaces Elman's recurrent network unfolded in time. \relax }}{12}{figure.caption.11}
\contentsline {figure}{\numberline {3.4}{\ignorespaces Clockwork-RNN. \relax }}{16}{figure.caption.12}
\addvspace {4\p@ }
\contentsline {figure}{\numberline {4.1}{\ignorespaces Sample output from Dstat.\relax }}{18}{figure.caption.13}
\contentsline {figure}{\numberline {4.2}{\ignorespaces Robotic arm in BEPUPhysics 3D physics simulator.\relax }}{19}{figure.caption.14}
\addvspace {4\p@ }
\addvspace {4\p@ }
\contentsline {figure}{\numberline {6.1}{\ignorespaces Total error of predicting goniometric function with TDNN and various sliding window sizes.\relax }}{26}{figure.caption.18}
\contentsline {figure}{\numberline {6.2}{\ignorespaces Total error of predicting goniometric function with SRN trained by TBPTT with various unfolding depth.\relax }}{27}{figure.caption.19}
\contentsline {figure}{\numberline {6.3}{\ignorespaces Total error of predicting goniometric function with CW-RNN trained by TBPTT with various unfolding depth.\relax }}{27}{figure.caption.19}
\contentsline {figure}{\numberline {6.4}{\ignorespaces Tradeoff between time and error in goniometric function scenario.\relax }}{28}{figure.caption.20}
\contentsline {figure}{\numberline {6.5}{\ignorespaces Total error of predicting network traffic with TDNN and various sliding window sizes.\relax }}{29}{figure.caption.21}
\contentsline {figure}{\numberline {6.6}{\ignorespaces Total error of predicting network traffic with SRN trained by TBPTT with various unfolding depth.\relax }}{29}{figure.caption.21}
\contentsline {figure}{\numberline {6.7}{\ignorespaces Total error of predicting network traffic with CW-RNN trained by TBPTT with various unfolding depth.\relax }}{29}{figure.caption.21}
\contentsline {figure}{\numberline {6.8}{\ignorespaces Tradeoff between time and error in network usage scenario.\relax }}{30}{figure.caption.22}
\contentsline {figure}{\numberline {6.9}{\ignorespaces Total error of predicting manipulator's claw position with TDNN and various sliding window sizes.\relax }}{31}{figure.caption.23}
\contentsline {figure}{\numberline {6.10}{\ignorespaces Total error of predicting manipulator's claw position with SRN trained by TBPTT with various unfolding depth.\relax }}{31}{figure.caption.24}
\contentsline {figure}{\numberline {6.11}{\ignorespaces Total error of predicting manipulator's claw position with CW-RNN trained by TBPTT with various unfolding depth.\relax }}{32}{figure.caption.25}
\contentsline {figure}{\numberline {6.12}{\ignorespaces Tradeoff between time and error in robotic arm scenario.\relax }}{33}{figure.caption.26}
\addvspace {4\p@ }
\addvspace {4\p@ }
